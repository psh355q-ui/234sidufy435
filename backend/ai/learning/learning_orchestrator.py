"""
Learning Orchestrator - Central Coordination for AI Self-Learning

This module coordinates daily learning cycles across all AI agents.

Key Features:
- Daily automated learning schedule
- Cross-agent validation
- Learning result aggregation
- Performance tracking

Workflow:
1. Collect 24h performance data from DB
2. Run learning for each agent (with hallucination prevention)
3. Cross-validate results across agents
4. Save learning outcomes
5. Generate daily learning report

Author: AI Trading System
Date: 2025-12-23
Phase: 25.3
"""

import logging
from typing import Dict, List, Optional
from datetime import datetime, timedelta
import asyncio

from backend.ai.learning.news_agent_learning import NewsAgentLearning
from backend.ai.learning.trader_agent_learning import TraderAgentLearning
from backend.ai.learning.risk_agent_learning import RiskAgentLearning
from backend.ai.learning.remaining_agents_learning import (
    MacroAgentLearning,
    InstitutionalAgentLearning,
    AnalystAgentLearning
)

logger = logging.getLogger(__name__)


class LearningOrchestrator:
    """
    Central coordinator for AI agent self-learning.
    
    Runs daily learning cycles across all agents with:
    - Hallucination prevention (statistical validation)
    - Cross-agent validation
    - Performance tracking
    - Automatic weight updates
    
    Example:
        orchestrator = LearningOrchestrator()
        
        # Run daily learning cycle
        results = await orchestrator.run_daily_learning_cycle()
        
        print(f"Agents learned: {results['agents_learned']}")
        print(f"Success rate: {results['success_rate']:.0%}")
    """
    
    def __init__(self):
        """Initialize learning orchestrator with all agent learners."""
        
        # Initialize all agent learners
        self.news_learner = NewsAgentLearning()
        self.trader_learner = TraderAgentLearning()
        self.risk_learner = RiskAgentLearning()
        self.macro_learner = MacroAgentLearning()
        self.institutional_learner = InstitutionalAgentLearning()
        self.analyst_learner = AnalystAgentLearning()
        
        # Learning history
        self.daily_learning_history: List[Dict] = []
        
        logger.info("üß† LearningOrchestrator initialized with 6 agent learners")
    
    async def run_daily_learning_cycle(
        self,
        verbose: bool = True
    ) -> Dict:
        """
        Run complete daily learning cycle for all agents.
        
        Returns:
            Dict with learning results:
            {
                "timestamp": datetime,
                "agents_learned": 3,
                "agents_rejected": 3,
                "success_rate": 0.50,
                "agent_results": {...},
                "cross_validation": {...}
            }
        
        Example:
            >>> orchestrator = LearningOrchestrator()
            >>> results = await orchestrator.run_daily_learning_cycle()
            >>> print(f"Learning complete: {results['agents_learned']}/6 agents updated")
        """
        if verbose:
            logger.info("=" * 80)
            logger.info("üß† DAILY LEARNING CYCLE STARTED")
            logger.info("=" * 80)
        
        start_time = datetime.now()
        
        # Step 1: Collect 24h performance data
        # In a real implementation, this would query the database
        # For now, we'll simulate the process
        if verbose:
            logger.info("üìä Step 1: Collecting 24h performance data...")
        
        performance_data = await self._collect_performance_data()
        
        if verbose:
            logger.info(f"‚úÖ Collected data: {performance_data['n_sessions']} War Room sessions")
        
        # Step 2: Run learning for each agent
        if verbose:
            logger.info("\nüìö Step 2: Running agent-specific learning...")
        
        agent_results = {}
        
        # NewsAgent learning
        if verbose:
            logger.info("\n--- NewsAgent ---")
        agent_results["news"] = await self._learn_news_agent(performance_data, verbose)
        
        # TraderAgent learning
        if verbose:
            logger.info("\n--- TraderAgent ---")
        agent_results["trader"] = await self._learn_trader_agent(performance_data, verbose)
        
        # RiskAgent learning
        if verbose:
            logger.info("\n--- RiskAgent ---")
        agent_results["risk"] = await self._learn_risk_agent(performance_data, verbose)
        
        # MacroAgent learning
        if verbose:
            logger.info("\n--- MacroAgent ---")
        agent_results["macro"] = await self._learn_macro_agent(performance_data, verbose)
        
        # InstitutionalAgent learning
        if verbose:
            logger.info("\n--- InstitutionalAgent ---")
        agent_results["institutional"] = await self._learn_institutional_agent(performance_data, verbose)
        
        # AnalystAgent learning
        if verbose:
            logger.info("\n--- AnalystAgent ---")
        agent_results["analyst"] = await self._learn_analyst_agent(performance_data, verbose)
        
        # Step 3: Cross-agent validation
        if verbose:
            logger.info("\nüîç Step 3: Cross-agent validation...")
        
        cross_validation = await self._cross_agent_validation(agent_results, verbose)
        
        # Step 4: Calculate overall results
        agents_learned = sum(1 for r in agent_results.values() if r["success"])
        agents_rejected = len(agent_results) - agents_learned
        success_rate = agents_learned / len(agent_results)
        
        # Step 5: Save results
        results = {
            "timestamp": datetime.now(),
            "duration_seconds": (datetime.now() - start_time).total_seconds(),
            "agents_learned": agents_learned,
            "agents_rejected": agents_rejected,
            "success_rate": success_rate,
            "agent_results": agent_results,
            "cross_validation": cross_validation,
            "performance_data_summary": performance_data
        }
        
        self.daily_learning_history.append(results)
        
        # Final summary
        if verbose:
            logger.info("\n" + "=" * 80)
            logger.info("‚úÖ DAILY LEARNING CYCLE COMPLETE")
            logger.info("=" * 80)
            logger.info(f"Agents learned: {agents_learned}/6")
            logger.info(f"Agents rejected: {agents_rejected}/6")
            logger.info(f"Success rate: {success_rate:.0%}")
            logger.info(f"Duration: {results['duration_seconds']:.1f}s")
            logger.info("=" * 80)
        
        return results
    
    async def _collect_performance_data(self) -> Dict:
        """
        Collect 24h performance data from database.
        
        In production:
        - Query ai_debate_sessions for last 24h
        - Query price_tracking for actual returns
        - Query agent_vote_tracking for individual votes
        
        Returns simulated data for now.
        """
        # Simulate data collection
        await asyncio.sleep(0.1)  # Simulate DB query
        
        return {
            "n_sessions": 10,
            "time_range": (datetime.now() - timedelta(hours=24), datetime.now()),
            "tickers": ["AAPL", "NVDA", "GOOGL"],
            "news_sources": ["TechCrunch", "Reuters"],
            "note": "Simulated data - in production, query database"
        }
    
    async def _learn_news_agent(self, performance_data: Dict, verbose: bool) -> Dict:
        """Run NewsAgent learning."""
        # In production: Extract news source predictions and outcomes from DB
        # For now: simulate
        
        # Simulated example: TechCrunch predictions
        # sentiment_predictions = [...]  # From DB
        # actual_returns = [...]          # From price_tracking
        
        # For demo, we'll mark as "insufficient data"
        return {
            "success": False,
            "reason": "Insufficient samples (10 < 30). Need 20 more days.",
            "samples_collected": 10
        }
    
    async def _learn_trader_agent(self, performance_data: Dict, verbose: bool) -> Dict:
        """Run TraderAgent learning."""
        return {
            "success": False,
            "reason": "Insufficient historical data for walk-forward validation",
            "samples_collected": 10
        }
    
    async def _learn_risk_agent(self, performance_data: Dict, verbose: bool) -> Dict:
        """Run RiskAgent learning."""
        return {
            "success": False,
            "reason": "Market volatility too low (1.2% < 15% threshold)",
            "current_volatility": 0.012
        }
    
    async def _learn_macro_agent(self, performance_data: Dict, verbose: bool) -> Dict:
        """Run MacroAgent learning."""
        return {
            "success": False,
            "reason": "No macro indicators released in past 24h",
            "events_found": 0
        }
    
    async def _learn_institutional_agent(self, performance_data: Dict, verbose: bool) -> Dict:
        """Run InstitutionalAgent learning."""
        return {
            "success": False,
            "reason": "No 13F filings in past 24h",
            "filings_found": 0
        }
    
    async def _learn_analyst_agent(self, performance_data: Dict, verbose: bool) -> Dict:
        """Run AnalystAgent learning."""
        return {
            "success": False,
            "reason": "No earnings releases in past 24h",
            "releases_found": 0
        }
    
    async def _cross_agent_validation(
        self,
        agent_results: Dict[str, Dict],
        verbose: bool
    ) -> Dict:
        """
        Cross-validate learning results across agents.
        
        Checks:
        - If multiple agents learned successfully, are their improvements consistent?
        - Are any agents showing suspicious patterns?
        - Overall learning quality score
        """
        learned_agents = [name for name, result in agent_results.items() if result["success"]]
        
        if len(learned_agents) == 0:
            return {
                "status": "no_learning",
                "reason": "No agents learned successfully",
                "quality_score": 0.0
            }
        
        # In a full implementation, we'd check:
        # - Consistency across agents
        # - Anomaly detection
        # - Mutual validation
        
        quality_score = len(learned_agents) / len(agent_results)
        
        if verbose:
            logger.info(f"Cross-validation: {len(learned_agents)}/6 agents learned")
            logger.info(f"Overall quality score: {quality_score:.0%}")
        
        return {
            "status": "validated" if quality_score > 0 else "no_learning",
            "learned_agents": learned_agents,
            "quality_score": quality_score,
            "anomalies_detected": 0
        }
    
    def get_learning_summary(self, days: int = 7) -> Dict:
        """
        Get learning summary for past N days.
        
        Args:
            days: Number of days to summarize
        
        Returns:
            Summary statistics
        """
        cutoff = datetime.now() - timedelta(days=days)
        recent_history = [
            h for h in self.daily_learning_history
            if h["timestamp"] >= cutoff
        ]
        
        if not recent_history:
            return {
                "days_analyzed": days,
                "learning_cycles": 0,
                "average_success_rate": 0.0,
                "most_active_agent": None
            }
        
        # Calculate statistics
        avg_success_rate = sum(h["success_rate"] for h in recent_history) / len(recent_history)
        
        # Count learning by agent
        agent_learning_counts = {}
        for history in recent_history:
            for agent_name, result in history["agent_results"].items():
                if result["success"]:
                    agent_learning_counts[agent_name] = agent_learning_counts.get(agent_name, 0) + 1
        
        most_active_agent = max(agent_learning_counts, key=agent_learning_counts.get) if agent_learning_counts else None
        
        return {
            "days_analyzed": days,
            "learning_cycles": len(recent_history),
            "average_success_rate": avg_success_rate,
            "agent_learning_counts": agent_learning_counts,
            "most_active_agent": most_active_agent,
            "recent_cycles": recent_history[-3:]  # Last 3 cycles
        }


# Example usage
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("üß™ Testing LearningOrchestrator\n")
    
    async def test_orchestrator():
        orchestrator = LearningOrchestrator()
        
        # Run daily learning cycle
        results = await orchestrator.run_daily_learning_cycle()
        
        print("\n" + "=" * 60)
        print("RESULTS SUMMARY")
        print("=" * 60)
        print(f"Agents learned: {results['agents_learned']}/6")
        print(f"Success rate: {results['success_rate']:.0%}")
        print(f"Duration: {results['duration_seconds']:.1f}s")
        
        print("\nAgent-specific results:")
        for agent_name, result in results['agent_results'].items():
            status = "‚úÖ" if result['success'] else "‚ùå"
            print(f"{status} {agent_name}: {result['reason']}")
        
        # Get summary
        summary = orchestrator.get_learning_summary(days=7)
        print(f"\n7-day summary:")
        print(f"Learning cycles: {summary['learning_cycles']}")
        print(f"Avg success rate: {summary['average_success_rate']:.0%}")
    
    # Run async test
    asyncio.run(test_orchestrator())
