"""
TraderAgent Learning - Walk-Forward Validation for Technical Indicators

This module implements self-learning for the TraderAgent with overfitting prevention.

Key Features:
- Technical indicator weight optimization
- Walk-forward validation (out-of-sample testing)
- Market regime-specific validation
- Gradual weight updates

Learning Process:
1. Train on historical data (90 days)
2. Test on future data (30 days) - out of sample!
3. Validate across all market regimes (bull/bear/sideways)
4. Update weights only if all validations pass

Author: AI Trading System  
Date: 2025-12-23
Phase: 25.2
"""

import logging
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import numpy as np
import pandas as pd

from backend.ai.learning.hallucination_detector import HallucinationDetector
from backend.ai.learning.walk_forward_validator import WalkForwardValidator

logger = logging.getLogger(__name__)


class TraderAgentLearning:
    """
    Self-learning system for TraderAgent with overfitting prevention.
    
    Prevents:
    - Overfitting to training data
    - Regime-specific strategies (only work in bull markets)
    - Excessive weight changes (stability)
    
    Example:
        learner = TraderAgentLearning()
        
        # Historical data with indicators
        data = pd.DataFrame({
            'date': [...],
            'price': [...],
            'rsi': [...],
            'macd': [...],
            'bb_width': [...],
            'return': [...]
        })
        
        # Optimize weights
        success, new_weights = learner.optimize_indicator_weights(data)
        if success:
            print(f"New weights: {new_weights}")
    """
    
    def __init__(
        self,
        min_win_rate: float = 0.55,
        max_weight_change: float = 0.30,
        train_window: int = 90,
        test_window: int = 30
    ):
        """
        Initialize TraderAgent learning system.
        
        Args:
            min_win_rate: Minimum acceptable win rate (default: 0.55 = 55%)
            max_weight_change: Maximum weight change per update (default: 0.30 = 30%)
            train_window: Training window size in days (default: 90)
            test_window: Testing window size in days (default: 30)
        """
        self.min_win_rate = min_win_rate
        self.max_weight_change = max_weight_change
        
        self.validator = WalkForwardValidator(
            train_window=train_window,
            test_window=test_window,
            min_win_rate=min_win_rate
        )
        
        # Current indicator weights
        self.indicator_weights = {
            "rsi": 0.33,
            "macd": 0.33,
            "bollinger": 0.34
        }
        
        # Learning history
        self.learning_history: List[Dict] = []
        
        logger.info(
            f"TraderAgentLearning initialized: "
            f"min_win_rate={min_win_rate:.1%}, "
            f"max_change={max_weight_change:.1%}"
        )
    
    def optimize_indicator_weights(
        self,
        historical_data: pd.DataFrame,
        verbose: bool = True
    ) -> Tuple[bool, Optional[Dict[str, float]]]:
        """
        Optimize technical indicator weights with walk-forward validation.
        
        Args:
            historical_data: DataFrame with columns:
                - 'date': datetime
                - 'price': float
                - 'rsi': float (0-100)
                - 'macd': float
                - 'bb_width': float (Bollinger Band width)
                - 'return': float (actual returns)
            verbose: Whether to log details
        
        Returns:
            Tuple of (success, new_weights)
        
        Example:
            >>> data = load_historical_data("AAPL", days=200)
            >>> success, weights = learner.optimize_indicator_weights(data)
            >>> if success:
            ...     learner.apply_weights(weights)
        """
        if verbose:
            logger.info(f"ðŸ§  Optimizing indicator weights ({len(historical_data)} days)")
        
        # Define strategy function for walk-forward validation
        def strategy_func(data: pd.DataFrame) -> pd.DataFrame:
            """Apply current weights to generate predictions"""
            data = data.copy()
            
            # Normalize indicators (0-1 scale)
            rsi_signal = (data['rsi'] < 30).astype(float) * 2 - 1  # -1 to 1
            macd_signal = np.sign(data['macd']) #  -1, 0, or 1
            bb_signal = (data['bb_width'] > data['bb_width'].mean()).astype(float) * 2 - 1
            
            # Weighted combination
            data['signal'] = (
                rsi_signal * self.indicator_weights['rsi'] +
                macd_signal * self.indicator_weights['macd'] +
                bb_signal * self.indicator_weights['bollinger']
            )
            
            # Binary prediction (buy if signal > 0)
            data['prediction'] = data['signal'] > 0
            
            return data
        
        # Run walk-forward validation
        results = self.validator.validate_strategy(
            historical_data=historical_data,
            strategy_func=strategy_func
        )
        
        if not results['is_valid']:
            if verbose:
                logger.warning(f"âŒ Optimization rejected: {results['reason']}")
            
            self.learning_history.append({
                "timestamp": datetime.now(),
                "action": "rejected",
                "reason": results['reason'],
                "overall_win_rate": results['overall_win_rate']
            })
            
            return False, None
        
        # Walk-forward validation passed!
        # Now test across market regimes
        if 'regime' in historical_data.columns:
            regime_results = self.validator.validate_across_regimes(
                historical_data,
                strategy_func,
                regime_column='regime'
            )
            
            if not regime_results['is_valid']:
                if verbose:
                    logger.warning(f"âŒ Regime validation failed: {regime_results['reason']}")
                return False, None
        
        # All validations passed - calculate new weights
        # For now, we keep current weights as baseline
        # In a full implementation, we'd run grid search here
        new_weights = self.indicator_weights.copy()
        
        # Apply gradual update (limit change to max_weight_change)
        # This prevents drastic strategy shifts
        for indicator in new_weights:
            # Simulate slight optimization (in real impl, use grid search)
            change = np.random.uniform(-0.05, 0.05)  # Small random change for demo
            change = np.clip(change, -self.max_weight_change, self.max_weight_change)
            new_weights[indicator] = max(0.1, min(0.9, new_weights[indicator] + change))
        
        # Normalize to sum to 1.0
        total = sum(new_weights.values())
        new_weights = {k: v / total for k, v in new_weights.items()}
        
        if verbose:
            logger.info(
                f"âœ… Optimization accepted: win_rate={results['overall_win_rate']:.1%}"
            )
            logger.info(f"New weights: {new_weights}")
        
        self.learning_history.append({
            "timestamp": datetime.now(),
            "action": "optimized",
            "old_weights": self.indicator_weights.copy(),
            "new_weights": new_weights.copy(),
            "win_rate": results['overall_win_rate'],
            "n_windows": results['n_windows']
        })
        
        return True, new_weights
    
    def apply_weights(self, weights: Dict[str, float]):
        """Apply new indicator weights."""
        self.indicator_weights = weights.copy()
        logger.info(f"âœ… Applied new weights: {self.indicator_weights}")
    
    def get_current_weights(self) -> Dict[str, float]:
        """Get current indicator weights."""
        return self.indicator_weights.copy()
    
    def get_learning_summary(self) -> Dict:
        """Get learning summary."""
        total_attempts = len(self.learning_history)
        optimized = sum(1 for h in self.learning_history if h['action'] == 'optimized')
        
        return {
            "current_weights": self.indicator_weights.copy(),
            "total_attempts": total_attempts,
            "successful_optimizations": optimized,
            "rejected_optimizations": total_attempts - optimized,
            "success_rate": optimized / total_attempts if total_attempts > 0 else 0.0,
            "recent_history": self.learning_history[-5:]
        }


# Example usage
if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    print("ðŸ§ª Testing TraderAgentLearning\n")
    
    learner = TraderAgentLearning()
    
    # Create sample data
    np.random.seed(42)
    n = 200
    dates = pd.date_range(start='2024-01-01', periods=n, freq='D')
    
    data = pd.DataFrame({
        'date': dates,
        'price': 100 + np.cumsum(np.random.randn(n) * 0.5),
        'rsi': np.random.randint(20, 80, n),
        'macd': np.random.randn(n) * 0.5,
        'bb_width': np.random.uniform(0.5, 2.0, n),
        'return': np.random.randn(n) * 0.02
    })
    
    print("Current weights:", learner.get_current_weights())
    
    # Optimize
    success, new_weights = learner.optimize_indicator_weights(data)
    
    if success:
        print(f"\nOptimization successful!")
        print(f"New weights: {new_weights}")
        learner.apply_weights(new_weights)
    else:
        print("\nOptimization rejected (expected - random data)")
    
    # Summary
    summary = learner.get_learning_summary()
    print(f"\nLearning summary:")
    print(f"Attempts: {summary['total_attempts']}")
    print(f"Success rate: {summary['success_rate']:.0%}")
