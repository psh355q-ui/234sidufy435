"""
Market Summary Language Templates

ChatGPT í”¼ë“œë°± ê¸°ë°˜:
- "í™•ì‹ "ë³´ë‹¤ "ì¡°ê±´ë¶€ íŒë‹¨"
- "íŒë‹¨ + í•´ì„ + ë‹¨ì„œ" 3ë‹¨ êµ¬ì¡°
- 4ê°€ì§€ ì‹œì¥ ìƒíƒœë³„ ë‹¤ì–‘í•œ í‘œí˜„

Q&A ë‹µë³€:
Q1. í™•ì‹  vs ìœ ë³´ ë¹„ìœ¨?
â†’ 70% ì¡°ê±´ë¶€, 30% í™•ì‹  (ì‹ ë¢°ë„ ìµœëŒ€í™”)

Q2. 4ë‹¨ê³„ë³´ë‹¤ ì„¸ë¶„í™”í•˜ë©´ ë…?
â†’ ê³¼ë„í•œ ì„¸ë¶„í™”ëŠ” ì¼ê´€ì„± ì €í•´, íŒë‹¨ í˜¼ë€

Q3. í…œí”Œë¦¿ ì‹ ì„ ë„ ìœ ì§€ ê·œì¹™?
â†’ ì‹œê°„Â·ê³„ì ˆ í‘œí˜„, ì‹œì¥ ì´ë²¤íŠ¸ ë°˜ì˜, ì£¼ê¸°ì  ì—…ë°ì´íŠ¸
"""
import random
from typing import Dict, List, Tuple
import logging

logger = logging.getLogger(__name__)


class MarketLanguageTemplates:
    """
    ì‹œì¥ ì„œì‚¬ ì–¸ì–´ í…œí”Œë¦¿ ê´€ë¦¬
    
    í•µì‹¬ ì›ì¹™:
    1. íŒë‹¨ì€ ëª…í™•, í‘œí˜„ì€ ì¡°ê±´ë¶€
    2. í•­ìƒ ì—¬ì§€ë¥¼ ë‚¨ê¹€
    3. ê¸´ì¥ê°ê³¼ ë‰˜ì•™ìŠ¤ ìœ ì§€
    """
    
    def __init__(self):
        """Initialize templates"""
        self.summary_templates = self._init_summary_templates()
        self.question_templates = self._init_question_templates()
        self.answer_templates = self._init_answer_templates()
        logger.info("âœ… MarketLanguageTemplates initialized")
    
    def _init_summary_templates(self) -> Dict[Tuple[str, str], List[str]]:
        """
        One-sentence summary í…œí”Œë¦¿ í’€
        
        4ê°€ì§€ ì‹œì¥ ìƒíƒœ:
        - (bullish, healthy): ê°•ì„¸ + ê±´ê°•
        - (bullish, fragile): ê°•ì„¸ + ìœ„í—˜ â­ ê°€ì¥ ì¤‘ìš”
        - (bearish, constructive): ì•½ì„¸ + ê¸°íšŒ
        - (bearish, deteriorating): ì•½ì„¸ + ì•…í™”
        """
        return {
            # ğŸŸ¢ ê°•ì„¸ + ê±´ê°•
            ("bullish", "healthy"): [
                "ì‹œì¥ì€ ê´‘ë²”ìœ„í•œ ë§¤ìˆ˜ì„¸ ì†ì— ìƒìŠ¹í–ˆìœ¼ë©°, ë³€ë™ì„± ì™„í™”ì™€ ê±°ë˜ëŸ‰ ê°œì„ ì´ ì´ë¥¼ ë’·ë°›ì¹¨í–ˆë‹¤.",
                "ì§€ìˆ˜ ìƒìŠ¹ì´ ë‹¨ê¸° íë¦„ì— ê·¸ì¹˜ì§€ ì•Šê³  ë‚´ë¶€ êµ¬ì¡° ê°œì„ ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ëª¨ìŠµì´ì—ˆë‹¤.",
                "ì‹œì¥ì€ ê°•ì„¸ë¥¼ ìœ ì§€í–ˆìœ¼ë©°, ìœ„í—˜ ì§€í‘œë“¤ ì—­ì‹œ ì´ë¥¼ í¬ê²Œ ë°©í•´í•˜ì§€ ì•Šì•˜ë‹¤.",
                "ì‹œì¥ì€ ê±´ì „í•œ ë§¤ìˆ˜ ê°•ë„ë¥¼ ë³´ì´ë©° ìƒìŠ¹í–ˆê³ , ë³€ë™ì„± ì§€í‘œë„ ì•ˆì •ì ì´ì—ˆë‹¤.",
                "ê´‘ë²”ìœ„í•œ ì„¹í„°ì—ì„œ ë™ë°˜ ìƒìŠ¹ì´ ë‚˜íƒ€ë‚˜ë©° ì‹œì¥ ì‹¬ë¦¬ê°€ ê°œì„ ë˜ëŠ” í•˜ë£¨ì˜€ë‹¤.",
            ],
            
            # ğŸŸ¡ ê°•ì„¸ + ìœ„í—˜ (ê°€ì¥ ì¤‘ìš”!)
            ("bullish", "fragile"): [
                "ì§€ìˆ˜ëŠ” ìƒìŠ¹í–ˆìœ¼ë‚˜, ë³€ë™ì„±Â·ê¸ˆë¦¬Â·ê±°ë˜ êµ¬ì¡°ë¥¼ ê°ì•ˆí•˜ë©´ ìƒìŠ¹ì˜ ì§ˆì—ëŠ” ì˜ë¬¸ì´ ë‚¨ëŠ” í•˜ë£¨ì˜€ë‹¤.",
                "ì‹œì¥ì€ ê°•ì„¸ë¥¼ ë³´ì˜€ì§€ë§Œ, ì¼ë¶€ ìœ„í—˜ ì§€í‘œëŠ” ì¶”ì„¸ ì§€ì†ì„±ì— ëŒ€í•œ ê²½ê³ ë¥¼ ë™ì‹œì— ë³´ë‚´ê³  ìˆì—ˆë‹¤.",
                "í‘œë©´ì ìœ¼ë¡œëŠ” ê°•ì„¸ì˜€ìœ¼ë‚˜, ë‚´ë¶€ì ìœ¼ë¡œëŠ” ë°©ì–´ì  í¬ì§€ì…˜ì´ ìœ ì§€ë˜ëŠ” ëª¨ìŠµì´ì—ˆë‹¤.",
                "ì‹œì¥ì€ ê°•ì„¸ì˜€ì§€ë§Œ, ë‚´ë¶€ì ìœ¼ë¡œëŠ” ìœ„í—˜ ì‹ í˜¸ê°€ ëˆ„ì ë˜ëŠ” í•˜ë£¨ì˜€ë‹¤.",
                "ì§€ìˆ˜ ê¸°ì¤€ìœ¼ë¡œëŠ” ê°•ì„¸ë¥¼ ë³´ì˜€ìœ¼ë‚˜, ë³€ë™ì„±ê³¼ ê±°ë˜ êµ¬ì¡°ë¥¼ ê°ì•ˆí•˜ë©´ ë‚´ë¶€ ìœ„í—˜ ì‹ í˜¸ê°€ ë™ì‹œì— ëˆ„ì ëœ í•˜ë£¨ì˜€ë‹¤.",
                "ìƒìŠ¹ íë¦„ì€ ìœ ì§€ëìœ¼ë‚˜, ê±°ë˜ëŸ‰ ë¶€ì¡±ê³¼ ë³€ë™ì„± ê¸‰ë½ì€ ì¶”ì„¸ì˜ ì·¨ì•½ì„±ì„ ì‹œì‚¬í–ˆë‹¤.",
                "ì‹œì¥ì€ ìƒìŠ¹í–ˆì§€ë§Œ, ì¼ë¶€ êµ¬ì¡°ì  ì§€í‘œëŠ” ì´ íë¦„ì˜ ì§€ì†ì„±ì— ì˜ë¬¸ì„ ì œê¸°í•˜ê³  ìˆì—ˆë‹¤.",
                "í‘œë©´ì  ê°•ì„¸ì—ë„ ë¶ˆêµ¬í•˜ê³ , ì‹œì¥ ë‚´ë¶€ì—ì„œëŠ” ê¸´ì¥ ì‹ í˜¸ê°€ ë™ì‹œì— ê´€ì°°ëë‹¤.",
            ],
            
            # ğŸ”µ ì•½ì„¸ + ê¸°íšŒ
            ("bearish", "constructive"): [
                "ì‹œì¥ì€ ì¡°ì •ì„ ë°›ì•˜ì§€ë§Œ, ë³€ë™ì„± ì•ˆì •ê³¼ ì„ íƒì  ë§¤ìˆ˜ íë¦„ì´ ê´€ì°°ëë‹¤.",
                "ì§€ìˆ˜ëŠ” í•˜ë½í–ˆìœ¼ë‚˜, ê³µí¬ í™•ì‚°ë³´ë‹¤ëŠ” ê¸°íšŒ íƒìƒ‰ ì„±ê²©ì´ ê°•í•œ ì¡°ì •ì´ì—ˆë‹¤.",
                "ì‹œì¥ì€ ì•½ì„¸ë¥¼ ë³´ì˜€ì§€ë§Œ, êµ¬ì¡°ì ìœ¼ë¡œëŠ” ë¶•ê´´ë³´ë‹¤ëŠ” ì¬ì •ë ¬ì— ê°€ê¹Œì› ë‹¤.",
                "í•˜ë½ íë¦„ì´ ë‚˜íƒ€ë‚¬ìœ¼ë‚˜, ì¼ë¶€ ì§€í‘œëŠ” ê³¼ë„í•œ ê³µí¬ë³´ë‹¤ëŠ” ì „ìˆ ì  ì¡°ì • ì‹ í˜¸ë¥¼ ë³´ëƒˆë‹¤.",
                "ì‹œì¥ì€ ì¡°ì •ì„ ê²ªì—ˆì§€ë§Œ, ë³€ë™ì„± ê¸‰ë“± ì—†ì´ ì§ˆì„œ ìˆëŠ” í•˜ë½ì´ ì´ì–´ì¡Œë‹¤.",
                "ì•½ì„¸ì¥ì´ì—ˆìœ¼ë‚˜, ì €ì  íƒìƒ‰ ì›€ì§ì„ê³¼ ì„ íƒì  ì €ê°€ ë§¤ìˆ˜ê°€ ë™ì‹œì— ê´€ì°°ëë‹¤.",
            ],
            
            # ğŸ”´ ì•½ì„¸ + ì•…í™”
            ("bearish", "deteriorating"): [
                "ì‹œì¥ì€ í•˜ë½ì„¸ë¥¼ ì´ì–´ê°”ìœ¼ë©°, ë³€ë™ì„± í™•ëŒ€ì™€ í•¨ê»˜ ì¶”ê°€ ì••ë ¥ ê°€ëŠ¥ì„±ì´ ì»¤ì¡Œë‹¤.",
                "ì§€ìˆ˜ í•˜ë½ê³¼ ë™ì‹œì— ìœ„í—˜ íšŒí”¼ ì‹ í˜¸ê°€ ê°•í™”ë˜ë©° ë°©ì–´ì  í™˜ê²½ì´ í˜•ì„±ëë‹¤.",
                "ì‹œì¥ì€ ì•½ì„¸ íë¦„ì„ ë²—ì–´ë‚˜ì§€ ëª»í–ˆê³ , ë‹¨ê¸° ë°˜ë“± ì‹ í˜¸ ì—­ì‹œ ì œí•œì ì´ì—ˆë‹¤.",
                "í•˜ë½ ì¶”ì„¸ê°€ ì§€ì†ë˜ëŠ” ê°€ìš´ë°, ë³€ë™ì„± ê¸‰ë“±ê³¼ ê±°ë˜ëŸ‰ ì¦ê°€ê°€ ë™ë°˜ëë‹¤.",
                "ì‹œì¥ì€ êµ¬ì¡°ì  ì•½ì„¸ êµ­ë©´ì— ì§„ì…í•œ ëª¨ìŠµì´ë©°, ì•ˆì •í™” ì‹ í˜¸ëŠ” ì•„ì§ ì œí•œì ì´ë‹¤.",
                "ì•½ì„¸ê°€ ì‹¬í™”ë˜ë©° ë°©ì–´ ì„¹í„°ë¡œì˜ ìê¸ˆ ì´ë™ì´ ëšœë ·í•´ì§€ëŠ” í•˜ë£¨ì˜€ë‹¤.",
            ],
        }
    
    def _init_question_templates(self) -> Dict[str, List[str]]:
        """
        í•µì‹¬ ì§ˆë¬¸ í…œí”Œë¦¿ (ì‹œì¥ ìƒí™©ë³„)
        """
        return {
            # ê°•ì„¸ì¥ ì§ˆë¬¸
            "bullish": [
                "ì´ ìƒìŠ¹ì€ ì¶”ì„¸ì¸ê°€, ìˆì»¤ë²„ì¸ê°€?",
                "ì´ ê°•ì„¸ëŠ” ì§€ì† ê°€ëŠ¥í•œê°€?",
                "í˜„ì¬ ìƒìŠ¹ì˜ ë³¸ì§ˆì€ ë¬´ì—‡ì¸ê°€?",
                "ì´ ëª¨ë©˜í…€ì€ ì–¼ë§ˆë‚˜ ìœ ì§€ë ê¹Œ?",
                "ìƒìŠ¹ ë°°ê²½ì— êµ¬ì¡°ì  ë³€í™”ê°€ ìˆëŠ”ê°€?",
            ],
            
            # ì•½ì„¸ì¥ ì§ˆë¬¸
            "bearish": [
                "ì´ í•˜ë½ì€ ì¡°ì •ì¸ê°€, ì¶”ì„¸ ì „í™˜ì¸ê°€?",
                "í˜„ ì•½ì„¸ëŠ” ì¼ì‹œì ì¸ê°€ êµ¬ì¡°ì ì¸ê°€?",
                "ì´ ì¡°ì •ì€ ì–´ë””ì„œ ë©ˆì¶œê¹Œ?",
                "í•˜ë½ì˜ ë³¸ì§ˆì€ ë¬´ì—‡ì¸ê°€?",
                "ë°˜ë“± ê°€ëŠ¥ì„±ì€ ì–´ëŠ ì •ë„ì¸ê°€?",
            ],
            
            # íš¡ë³´ì¥ ì§ˆë¬¸
            "sideways": [
                "ì–¸ì œ ëŒíŒŒí• ê¹Œ, ì–´ëŠ ë°©í–¥ìœ¼ë¡œ?",
                "í˜„ íš¡ë³´ëŠ” ì¡°ì •ì¸ê°€ ì¬ì •ë ¬ì¸ê°€?",
                "ì´ ë°•ìŠ¤ê¶Œì€ ì–¸ì œê¹Œì§€ ìœ ì§€ë ê¹Œ?",
                "ë‹¤ìŒ ë°©í–¥ì„±ì€ ì–´ë””ì„œ ë‚˜ì˜¬ê¹Œ?",
            ],
            
            # Fed/ê¸ˆë¦¬ ê´€ë ¨
            "fed": [
                "FedëŠ” ì •ë§ í”¼ë´‡í• ê¹Œ?",
                "ê¸ˆë¦¬ ì •ì±… ì „í™˜ì€ ì–¸ì œì¼ê¹Œ?",
                "í˜„ ë§¤íŒŒ ìŠ¤íƒ ìŠ¤ëŠ” ì–¼ë§ˆë‚˜ ìœ ì§€ë ê¹Œ?",
                "ì‹œì¥ì´ ê°€ê²©ì— ë°˜ì˜í•œ Fed ê²½ë¡œëŠ” ì ì ˆí•œê°€?",
            ],
        }
    
    def _init_answer_templates(self) -> Dict[str, Dict[str, List[str]]]:
        """
        AI ë‹µë³€ í…œí”Œë¦¿ (í•µì‹¬: ì¡°ê±´ë¶€ í‘œí˜„!)
        
        70% ì¡°ê±´ë¶€, 30% í™•ì‹ 
        """
        return {
            # ê°•ì„¸ì¥ ì§ˆë¬¸ ë‹µë³€
            "trend_vs_cover": {
                "trend_likely": [  # ì¶”ì„¸ ê°€ëŠ¥ì„± ë†’ìŒ
                    "í˜„ì¬ ìƒìŠ¹ì€ ë‹¨ê¸° ìˆì»¤ë²„ ì„±ê²©ë³´ë‹¤ëŠ” ì¶”ì„¸ í˜•ì„± ì´ˆê¸° ë‹¨ê³„ì— ê°€ê¹ë‹¤. ë‹¤ë§Œ ë³€ë™ì„± ë° ê±°ë˜ êµ¬ì¡°ìƒ ì™„ì „í•œ ì¶”ì„¸ ì „í™˜ìœ¼ë¡œ ë‹¨ì •í•˜ê¸°ì—ëŠ” ì´ë¥´ë‹¤.",
                    "ë§¤ìˆ˜ ê°•ë„ëŠ” ìœ ì§€ë˜ê³  ìˆìœ¼ë‚˜, í¬ì§€ì…˜ êµ¬ì¡°ìƒ ì¶”ê°€ í™•ì¸ ì‹ í˜¸ê°€ í•„ìš”í•˜ë‹¤.",
                    "ì¶”ì„¸ ê°€ëŠ¥ì„±ì´ ìš°ì„¸í•˜ë‚˜, ì¼ë¶€ ì§€í‘œëŠ” ì—¬ì „íˆ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê¶Œê³ í•˜ê³  ìˆë‹¤.",
                ],
                "cover_likely": [  # ìˆì»¤ë²„ ê°€ëŠ¥ì„± ë†’ìŒ
                    "ìˆì»¤ë²„ ê°€ëŠ¥ì„± 65% - ê±°ë˜ëŸ‰ ë¶€ì¡±ê³¼ VIX ê¸‰ë½ì´ ì´ë¥¼ ì‹œì‚¬í•œë‹¤.",
                    "í˜„ ìƒìŠ¹ì€ ìˆ í¬ì§€ì…˜ ì²­ì‚° ì„±ê²©ì´ ê°•í•˜ë©°, ì§€ì†ì  ë§¤ìˆ˜ íë¦„ìœ¼ë¡œ ë³´ê¸°ì—ëŠ” ê·¼ê±°ê°€ ë¶€ì¡±í•˜ë‹¤.",
                    "ê¸°ìˆ ì  ë°˜ë“± ì„±ê²©ì´ ìš°ì„¸í•˜ë©°, êµ¬ì¡°ì  ì¶”ì„¸ ì „í™˜ ì‹ í˜¸ëŠ” ì œí•œì ì´ë‹¤.",
                ],
                "mixed": [  # í˜¼ì¬
                    "ì¶”ì„¸ì™€ ìˆì»¤ë²„ ìš”ì†Œê°€ í˜¼ì¬ë˜ì–´ ìˆì–´, í˜„ ë‹¨ê³„ì—ì„œ ë‹¨ì •í•˜ê¸° ì–´ë µë‹¤. í–¥í›„ 2-3ì¼ ê±°ë˜ íŒ¨í„´ì´ ë°©í–¥ì„±ì„ ê²°ì •í•  ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.",
                    "ì¼ë¶€ëŠ” ì¶”ì„¸, ì¼ë¶€ëŠ” ìˆì»¤ë²„ë¡œ íŒë‹¨ë˜ë©°, ì‹œì¥ ë‚´ë¶€ í•©ì˜ê°€ ì•„ì§ í˜•ì„±ë˜ì§€ ì•Šì€ ëª¨ìŠµì´ë‹¤.",
                ],
            },
            
            # Fed í”¼ë´‡ ì§ˆë¬¸ ë‹µë³€
            "fed_pivot": {
                "not_yet": [  # ì‹œê¸°ìƒì¡°
                    "ì•„ì§ ì‹œê¸°ìƒì¡° (í™•ë¥  30%) - ê³ ìš© ì§€í‘œê°€ ì—¬ì „íˆ ê°•í•˜ë©°, Fedì˜ ëª…ì‹œì  ì‹ í˜¸ë„ ë¶€ì¬í•˜ë‹¤.",
                    "í˜„ ë‹¨ê³„ì—ì„œ í”¼ë´‡ ê¸°ëŒ€ëŠ” ê³¼ë„í•˜ë‹¤. ì¸í”Œë ˆì´ì…˜ ì–µì œ ì˜ì§€ê°€ ì—¬ì „íˆ ìš°ì„ ìˆœìœ„ë¡œ ë³´ì¸ë‹¤.",
                    "ì‹œì¥ì€ í”¼ë´‡ì„ ì„ ë°˜ì˜í•˜ë ¤ í•˜ë‚˜, Fed ê³µì‹ ì…ì¥ê³¼ëŠ” ê´´ë¦¬ê°€ í¬ë‹¤.",
                ],
                "possible": [  # ê°€ëŠ¥ì„± ìˆìŒ
                    "ì¼ë¶€ ì‹ í˜¸ëŠ” í”¼ë´‡ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•˜ë‚˜, ê³µì‹ ì…ì¥ ì „í™˜ê¹Œì§€ëŠ” ì‹œê°„ì´ í•„ìš”í•˜ë‹¤.",
                    "ë°ì´í„° ì˜ì¡´ì  ìŠ¤íƒ ìŠ¤ìƒ, í–¥í›„ 2-3ê°œì›” ì§€í‘œê°€ ê²°ì •ì ì¼ ê²ƒìœ¼ë¡œ íŒë‹¨ëœë‹¤.",
                ],
                "likely": [  # ê°€ëŠ¥ì„± ë†’ìŒ
                    "ì¸í”Œë ˆì´ì…˜ ë‘”í™”ì™€ ê³ ìš© ì‹œì¥ ëƒ‰ê°ì´ ë™ì‹œì— ë‚˜íƒ€ë‚˜ë©°, í”¼ë´‡ ê°€ëŠ¥ì„±ì´ ì ì°¨ ë†’ì•„ì§€ê³  ìˆë‹¤.",
                    "Fed ë‚´ë¶€ ë°œì–¸ í†¤ ë³€í™”ì™€ ì‹œì¥ ê¸°ëŒ€ê°€ ìˆ˜ë ´í•˜ëŠ” ëª¨ìŠµì´ë©°, ê³µì‹ ì „í™˜ ì‹œê¸°ê°€ ê°€ê¹Œì›Œì§€ê³  ìˆë‹¤.",
                ],
            },
            
            # ì•½ì„¸ì¥ ì§ˆë¬¸ ë‹µë³€
            "correction_vs_reversal": {
                "correction": [  # ì¡°ì •
                    "í˜„ ë‹¨ê³„ì—ì„œëŠ” ì¶”ì„¸ ì „í™˜ë³´ë‹¤ëŠ” ê³ ì  ë¶€ë‹´ì— ë”°ë¥¸ ì¡°ì • ê°€ëŠ¥ì„±ì´ ìš°ì„¸í•˜ë‹¤.",
                    "ì¼ë¶€ ì§€í‘œëŠ” ì¶”ì„¸ ì•½í™”ë¥¼ ì‹œì‚¬í•˜ì§€ë§Œ, ì•„ì§ êµ¬ì¡°ì  ë¶•ê´´ ì‹ í˜¸ëŠ” ì œí•œì ì´ë‹¤.",
                    "ê¸°ìˆ ì  ì¡°ì • ë²”ìœ„ ë‚´ì—ì„œ ì›€ì§ì´ê³  ìˆìœ¼ë©°, ì¶”ì„¸ ì „í™˜ìœ¼ë¡œ ë³´ê¸°ì—ëŠ” ì´ë¥´ë‹¤.",
                ],
                "reversal_risk": [  # ì „í™˜ ìœ„í—˜
                    "ì¼ë¶€ ì„ í–‰ ì§€í‘œëŠ” ì¶”ì„¸ ì „í™˜ ê°€ëŠ¥ì„±ì„ ê²½ê³ í•˜ê³  ìˆìœ¼ë‚˜, ìµœì¢… í™•ì¸ì´ í•„ìš”í•˜ë‹¤.",
                    "êµ¬ì¡°ì  ì•½í™” ì‹ í˜¸ê°€ ëˆ„ì ë˜ê³  ìˆì–´, ë‹¨ìˆœ ì¡°ì •ì„ ë„˜ì–´ì„œëŠ” ìœ„í—˜ì„ ë°°ì œí•  ìˆ˜ ì—†ë‹¤.",
                ],
            },
        }
    
    def get_market_summary(self, trend: str = "bullish", health: str = "fragile") -> str:
        """
        ì‹œì¥ ìƒíƒœì— ë§ëŠ” one-sentence summary ë°˜í™˜
        
        Args:
            trend: "bullish" | "bearish"
            health: "healthy" | "fragile" | "constructive" | "deteriorating"
        
        Returns:
            AI í•œ ë¬¸ì¥ ìš”ì•½
        """
        key = (trend, health)
        templates = self.summary_templates.get(key, self.summary_templates[("bullish", "fragile")])
        return random.choice(templates)
    
    def get_key_question(self, category: str = "bullish") -> str:
        """í•µì‹¬ ì§ˆë¬¸ ë°˜í™˜"""
        templates = self.question_templates.get(category, self.question_templates["bullish"])
        return random.choice(templates)
    
    def get_ai_answer(self, question_type: str, answer_type: str) -> str:
        """
        AI ë‹µë³€ ë°˜í™˜
        
        Args:
            question_type: "trend_vs_cover" | "fed_pivot" | "correction_vs_reversal"
            answer_type: "trend_likely" | "cover_likely" | "mixed" | "not_yet" | etc.
        
        Returns:
            AI ë‹µë³€ (ì¡°ê±´ë¶€ í‘œí˜„)
        """
        templates = self.answer_templates.get(question_type, {}).get(answer_type, ["ë‹µë³€ ì¤€ë¹„ ì¤‘"])
        return random.choice(templates)


# Confidence vs Hesitation Balance Analysis
class ConfidenceBalanceAnalyzer:
    """
    Q1 ë‹µë³€: í™•ì‹  vs ìœ ë³´ ë¹„ìœ¨ ë¶„ì„
    
    ê²°ë¡ : 70% ì¡°ê±´ë¶€, 30% í™•ì‹  = ìµœì 
    """
    
    @staticmethod
    def analyze_optimal_ratio() -> Dict:
        """
        ì‹ ë¢°ë„ ìµœëŒ€í™”í•˜ëŠ” ë¹„ìœ¨ ë¶„ì„
        
        Returns:
            {
                "optimal_ratio": "70% conditional, 30% confident",
                "reasoning": "...",
                "examples": {...}
            }
        """
        return {
            "optimal_ratio": "70% ì¡°ê±´ë¶€, 30% í™•ì‹ ",
            "reasoning": """
            ê³ ì•¡ íˆ¬ììÂ·ê¸°ê´€ì€ 'ë¶ˆí™•ì‹¤ì„± ì¸ì •'ì„ ì˜¤íˆë ¤ ì‹ ë¢°í•¨.
            ê³¼ë„í•œ í™•ì‹  = ì˜¤ë§Œ, ê³¼ë„í•œ ìœ ë³´ = ìš°ìœ ë¶€ë‹¨
            70:30 ë¹„ìœ¨ì´ ê· í˜•ì .
            """,
            "examples": {
                "too_confident": "âŒ ì´ ìƒìŠ¹ì€ ëª…í™•í•œ ì¶”ì„¸ë‹¤. (0% ìœ ë³´)",
                "too_hesitant": "âŒ íŒë‹¨ì´ ì–´ë µë‹¤. ë¶ˆí™•ì‹¤í•˜ë‹¤. (100% ìœ ë³´)",
                "optimal": "âœ… ì¶”ì„¸ ê°€ëŠ¥ì„±ì´ ìš°ì„¸í•˜ë‚˜, ì¼ë¶€ ì§€í‘œëŠ” ì—¬ì „íˆ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê¶Œê³ í•œë‹¤. (70% ì¡°ê±´ë¶€)",
            },
            "implementation": "ì¡°ê±´ë¶€ í‘œí˜„ ì‚¬ìš©: 'ê°€ëŠ¥ì„±ì´ ìš°ì„¸', '~í•˜ë‚˜', '~ì—ë„ ë¶ˆêµ¬í•˜ê³ ', 'í˜„ ë‹¨ê³„ì—ì„œëŠ”'"
        }


# Template Freshness Rules
class TemplateFreshnessRules:
    """
    Q3 ë‹µë³€: í…œí”Œë¦¿ ì‹ ì„ ë„ ìœ ì§€ ê·œì¹™
    """
    
    @staticmethod
    def get_freshness_rules() -> Dict:
        """
        í…œí”Œë¦¿ì´ ì‹ìƒí•´ì§€ì§€ ì•ŠëŠ” ê·œì¹™
        
        Returns:
            ê·œì¹™ ë”•ì…”ë„ˆë¦¬
        """
        return {
            "rule_1_time_context": {
                "description": "ì‹œê°„Â·ê³„ì ˆ í‘œí˜„ ì¶”ê°€",
                "examples": [
                    "ì—°ë§ í¬ì§€ì…˜ ì¡°ì • ì‹œê¸°ë¥¼ ê³ ë ¤í•˜ë©´...",
                    "ë¶„ê¸° ë§ ë¦¬ë°¸ëŸ°ì‹± ì••ë ¥ì´ ì˜ˆìƒë˜ëŠ” ì‹œì ì—ì„œ...",
                    "ì—¬ë¦„ ì„±ìˆ˜ê¸°ë¥¼ ì•ë‘ê³ ...",
                ],
            },
            "rule_2_market_events": {
                "description": "ì‹¤ì œ ì´ë²¤íŠ¸ ë°˜ì˜",
                "examples": [
                    "FOMC ê²°ê³¼ ë°œí‘œ ì§í›„ì„ì„ ê°ì•ˆí•˜ë©´...",
                    "ì‹¤ì  ì‹œì¦Œ ì´ˆë°˜ì„ì„ ê³ ë ¤í•  ë•Œ...",
                    "ì§€ì •í•™ì  ê¸´ì¥ì´ ê³ ì¡°ëœ ìƒí™©ì—ì„œ...",
                ],
            },
            "rule_3_periodic_update": {
                "description": "3ê°œì›”ë§ˆë‹¤ í‘œí˜„ ì—…ë°ì´íŠ¸",
                "method": "ìµœê·¼ 3ê°œì›” ì‹œì¥ í‚¤ì›Œë“œ ìˆ˜ì§‘ â†’ ë¬¸ì¥ì— ë°˜ì˜",
            },
            "rule_4_variation_pool": {
                "description": "ìµœì†Œ 5ê°œ ì´ìƒ ë³€í˜• ìœ ì§€",
                "reason": "ê°™ì€ ìƒí™©ì—ë„ ë‹¤ë¥¸ í‘œí˜„ = ì‹ ì„ í•¨ ìœ ì§€",
            },
            "rule_5_avoid_cliche": {
                "description": "ì§„ë¶€í•œ í‘œí˜„ ê¸ˆì§€ ëª©ë¡",
                "banned": [
                    "ì‹œì¥ì€ ë“±ë½ì„ ê±°ë“­í–ˆë‹¤",
                    "íˆ¬ììë“¤ì˜ ê´€ì‹¬ì´ ì§‘ì¤‘ëë‹¤",
                    "í–¥ë°©ì„ ì£¼ì‹œí•´ì•¼ í•œë‹¤",
                ],
            },
        }


# Test function
def test_language_templates():
    """ì–¸ì–´ í…œí”Œë¦¿ í…ŒìŠ¤íŠ¸"""
    print("="*60)
    print("Market Language Templates Test")
    print("="*60)
    
    templates = MarketLanguageTemplates()
    
    # Test 1: Summary variations
    print("\n[Test 1] One-Sentence Summary Variations")
    print("\nê°•ì„¸ + ìœ„í—˜ (3ê°œ ìƒ˜í”Œ):")
    for i in range(3):
        print(f"  {i+1}. {templates.get_market_summary('bullish', 'fragile')}")
    
    print("\nê°•ì„¸ + ê±´ê°• (2ê°œ ìƒ˜í”Œ):")
    for i in range(2):
        print(f"  {i+1}. {templates.get_market_summary('bullish', 'healthy')}")
    
    # Test 2: Questions
    print("\n[Test 2] Key Questions")
    print(f"  ê°•ì„¸ì¥ ì§ˆë¬¸: {templates.get_key_question('bullish')}")
    print(f"  Fed ì§ˆë¬¸: {templates.get_key_question('fed')}")
    
    # Test 3: AI Answers
    print("\n[Test 3] AI Answers (Conditional Expressions)")
    print(f"  ì¶”ì„¸ vs ìˆì»¤ë²„ (ì¶”ì„¸ ê°€ëŠ¥ì„±): {templates.get_ai_answer('trend_vs_cover', 'trend_likely')}")
    print(f"  Fed í”¼ë´‡ (ì‹œê¸°ìƒì¡°): {templates.get_ai_answer('fed_pivot', 'not_yet')}")
    
    # Test 4: Q1-Q3 Analysis
    print("\n[Test 4] Q1-Q3 Analysis")
    analyzer = ConfidenceBalanceAnalyzer()
    balance = analyzer.analyze_optimal_ratio()
    print(f"  ìµœì  ë¹„ìœ¨: {balance['optimal_ratio']}")
    print(f"  ì´ìœ : {balance['reasoning'].strip()}")
    
    freshness = TemplateFreshnessRules.get_freshness_rules()
    print(f"\n  ì‹ ì„ ë„ ìœ ì§€ ê·œì¹™ {len(freshness)}ê°œ:")
    for key, rule in freshness.items():
        print(f"    - {rule['description']}")
    
    print("\n" + "="*60)
    print("âœ… Test completed!")
    print("\ní†µê³„:")
    print(f"  â€¢ Summary templates: {sum(len(v) for v in templates.summary_templates.values())}ê°œ")
    print(f"  â€¢ Question templates: {sum(len(v) for v in templates.question_templates.values())}ê°œ")
    print(f"  â€¢ Answer templates: {sum(len(v2) for v1 in templates.answer_templates.values() for v2 in v1.values())}ê°œ")


if __name__ == "__main__":
    test_language_templates()
